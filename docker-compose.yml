services:
  cluster-master:
    image: firasj/spark-docker-cluster
    container_name: cluster-master
    environment:
      - HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - YARN_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - PYSPARK_PYTHON=/app/.venv/bin/python
      - PYSPARK_DRIVER_PYTHON=/app/.venv/bin/python
    ports:
      - "8088:8088"
      - "4040:4040"
      - "19888:19888"
      - "9000:9000"
      - "9870:9870"
    volumes:
      - "./app:/app"
      - "./a.parquet:/app/a.parquet"
      - "./my-hadoop-config/capacity-scheduler.xml:/usr/local/hadoop/etc/hadoop/capacity-scheduler.xml"
      - "./my-hadoop-config/yarn-site.xml:/usr/local/hadoop/etc/hadoop/yarn-site.xml"
      - "./my-hadoop-config/container-executor.cfg:/usr/local/hadoop/etc/hadoop/container-executor.cfg"
    networks:
      - spark-cluster
    depends_on:
      cassandra-server:
        condition: service_healthy
      cluster-slave-1:
        condition: service_healthy
    hostname: cluster-master
    tty: true
    working_dir: /app
    entrypoint:
      - bash
      - /app/app.sh
    platform: linux/amd64
    
  cluster-slave-1:
    image: firasj/spark-docker-cluster
    container_name: cluster-slave-1
    environment:
      - HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - YARN_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - PYSPARK_PYTHON=/app/.venv/bin/python
      - PYSPARK_DRIVER_PYTHON=/app/.venv/bin/python
    volumes:
      - "./my-hadoop-config/capacity-scheduler.xml:/usr/local/hadoop/etc/hadoop/capacity-scheduler.xml"
      - "./my-hadoop-config/yarn-site.xml:/usr/local/hadoop/etc/hadoop/yarn-site.xml"
      - "./my-hadoop-config/container-executor.cfg:/usr/local/hadoop/etc/hadoop/container-executor.cfg"
    networks:
      - spark-cluster
    hostname: cluster-slave-1
    tty: true
    platform: linux/amd64
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f Worker || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
  cluster-slave-2:
    image: firasj/spark-docker-cluster
    container_name: cluster-slave-2
    environment:
      - HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - YARN_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - PYSPARK_PYTHON=/app/.venv/bin/python
      - PYSPARK_DRIVER_PYTHON=/app/.venv/bin/python
    volumes:
      - "./my-hadoop-config/capacity-scheduler.xml:/usr/local/hadoop/etc/hadoop/capacity-scheduler.xml"
      - "./my-hadoop-config/yarn-site.xml:/usr/local/hadoop/etc/hadoop/yarn-site.xml"
      - "./my-hadoop-config/container-executor.cfg:/usr/local/hadoop/etc/hadoop/container-executor.cfg"
    networks:
      - spark-cluster
    depends_on:
       - cluster-slave-1
    hostname: cluster-slave-2
    tty: true
    platform: linux/amd64

  cassandra-server:
    image: cassandra
    container_name: cassandra-server
    mem_limit: 4g  # Minimum 4GB for Cassandra
    environment:
      - MAX_HEAP_SIZE=1G
      - HEAP_NEWSIZE=256MG
      - CASSANDRA_MAX_HEAP_SIZE=512M  # JVM heap max
      - CASSANDRA_HEAP_NEWSIZE=256M   # JVM young generation
    ports:
      - "7000:7000"
      - "9042:9042"
    networks:
      - spark-cluster
    healthcheck:
      test: [ "CMD-SHELL", "cqlsh -e 'DESCRIBE keyspaces'" ]
      interval: 10s
      timeout: 5s
      retries: 20
    

networks:
  spark-cluster:
    driver: bridge