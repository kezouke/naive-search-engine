version: "3.9"

services:
  cluster-master:
    image: firasj/spark-docker-cluster
    container_name: cluster-master
    hostname: cluster-master
    environment:
      - HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - YARN_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - PYSPARK_PYTHON=/app/.venv/bin/python
      - PYSPARK_DRIVER_PYTHON=/app/.venv/bin/python
    ports:
      - "8088:8088"
      - "4040:4040"
      - "19888:19888"
      - "9000:9000"
      - "9870:9870"
      - "8032:8032"
    volumes:
      - ./app:/app
      - ./a.parquet:/app/a.parquet
      - ./my-hadoop-config/capacity-scheduler.xml:/usr/local/hadoop/etc/hadoop/capacity-scheduler.xml
      - ./my-hadoop-config/yarn-site.xml:/usr/local/hadoop/etc/hadoop/yarn-site.xml
      - ./my-hadoop-config/container-executor.cfg:/usr/local/hadoop/etc/hadoop/container-executor.cfg
    networks:
      - spark-cluster
    depends_on:
      cassandra-server:
        condition: service_healthy
      cluster-slave-1:
        condition: service_healthy
    tty: true
    working_dir: /app
    entrypoint:
      - bash
      - /app/app.sh
    platform: linux/amd64

  cluster-slave-1:
    image: firasj/spark-docker-cluster
    container_name: cluster-slave-1
    hostname: cluster-slave-1
    environment:
      - HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - YARN_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - PYSPARK_PYTHON=/app/.venv/bin/python
      - PYSPARK_DRIVER_PYTHON=/app/.venv/bin/python
    volumes:
      - ./my-hadoop-config/capacity-scheduler.xml:/usr/local/hadoop/etc/hadoop/capacity-scheduler.xml
      - ./my-hadoop-config/yarn-site.xml:/usr/local/hadoop/etc/hadoop/yarn-site.xml
      - ./my-hadoop-config/container-executor.cfg:/usr/local/hadoop/etc/hadoop/container-executor.cfg
    extra_hosts:
      - "cluster-master:172.18.0.5"
      - "cluster-slave-2:172.18.0.4"
    networks:
      - spark-cluster
    tty: true
    platform: linux/amd64
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f Worker || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s

  cluster-slave-2:
    image: firasj/spark-docker-cluster
    container_name: cluster-slave-2
    hostname: cluster-slave-2
    environment:
      - HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - YARN_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - PYSPARK_PYTHON=/app/.venv/bin/python
      - PYSPARK_DRIVER_PYTHON=/app/.venv/bin/python
    volumes:
      - ./my-hadoop-config/capacity-scheduler.xml:/usr/local/hadoop/etc/hadoop/capacity-scheduler.xml
      - ./my-hadoop-config/yarn-site.xml:/usr/local/hadoop/etc/hadoop/yarn-site.xml
      - ./my-hadoop-config/container-executor.cfg:/usr/local/hadoop/etc/hadoop/container-executor.cfg
    extra_hosts:
      - "cluster-master:172.18.0.5"
      - "cluster-slave-1:172.18.0.3"
    networks:
      - spark-cluster
    depends_on:
      - cluster-slave-1
    tty: true
    platform: linux/amd64

  cassandra-server:
    image: cassandra
    container_name: cassandra-server
    environment:
      - MAX_HEAP_SIZE=1G
      - HEAP_NEWSIZE=256MG
      - CASSANDRA_MAX_HEAP_SIZE=512M
      - CASSANDRA_HEAP_NEWSIZE=256M
    ports:
      - "7000:7000"
      - "9042:9042"
    networks:
      - spark-cluster
    healthcheck:
      test: [ "CMD-SHELL", "cqlsh -e 'DESCRIBE keyspaces'" ]
      interval: 10s
      timeout: 5s
      retries: 20

networks:
  spark-cluster:
    driver: bridge
