services:
  cluster-master:
    image: firasj/spark-docker-cluster
    container_name: cluster-master
    ports:
      - "8088:8088"
      - "4040:4040"
      - "19888:19888"
      - "9000:9000"
      - "9870:9870"
    volumes:
      - "./app:/app"
      - "./a.parquet:/app/a.parquet"
    networks:
      - spark-cluster
    depends_on:
      cassandra-server:
        condition: service_healthy
      cluster-slave-1:
        condition: service_healthy
    hostname: cluster-master
    tty: true
    working_dir: /app
    # You can comment the entrypoint to run the script manually inside the container
    entrypoint: 
      - bash
      - /app/app.sh
    platform: linux/amd64
    
  cluster-slave-1:
    image: firasj/spark-docker-cluster
    container_name: cluster-slave-1
    networks:
      - spark-cluster
    hostname: cluster-slave-1
    tty: true
    platform: linux/amd64
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f Worker || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
  #  cluster-slave-2:
#     image: firasj/spark-docker-cluster
#     container_name: cluster-slave-2
#     networks:
#       - spark-cluster
#     depends_on:
#       - cluster-slave-1
#     hostname: cluster-slave-2
#     tty: true

  cassandra-server:
    image: cassandra
    container_name: cassandra-server
    mem_limit: 4g  # Minimum 4GB for Cassandra
    environment:
      - MAX_HEAP_SIZE=1G
      - HEAP_NEWSIZE=256MG
      - CASSANDRA_MAX_HEAP_SIZE=512M  # JVM heap max
      - CASSANDRA_HEAP_NEWSIZE=256M   # JVM young generation
    ports:
      - "7000:7000"
      - "9042:9042"
    networks:
      - spark-cluster
    healthcheck:
      test: [ "CMD-SHELL", "cqlsh -e 'DESCRIBE keyspaces'" ]
      interval: 10s
      timeout: 5s
      retries: 20
    

networks:
  spark-cluster:
    driver: bridge